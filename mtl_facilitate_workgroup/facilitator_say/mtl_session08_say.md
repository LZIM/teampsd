---
title: "MTL Session 8 - Facilitator Say"
author: "Team PSD"
date: "September 2018"
output: 
  github_document: default
  html_document: default
  pdf_document: default
  word_document: default
  ioslides_presentation: default
  slidy_presentation: default
  powerpoint_presentation: default
---

<img src = "https://github.com/lzim/teampsd/blob/master/resources/logos/mtl_live_sq_sm.png"
     height = "175" width = "290">  

# [MTL Live Session 08](https://github.com/lzim/teampsd/blob/master/mtl_facilitate_workgroup/mtl_live_guide/mtl_live_session08_see.Rmd "MTL Live Session 08")

# Today we're modeling to learn how to test a dynamic hypothesis.
Hello! I'm __________ and I'm __________ [Co-facilitators introduce themselves]. Today we're modeling to learn how to test a dynamic hypothesis.

### As you can see in the Done/Do table at the top of the Learner See Guide:

## Done and Do (15 minutes)
<!-- Do/Done Tables -->
| <img src = "https://raw.githubusercontent.com/lzim/teampsd/hexagon_icons/np_hexagon-check-mark_309690_003F72.png" height = "80" width = "80"> **Done** | <img src = "https://raw.githubusercontent.com/lzim/teampsd/hexagon_icons/np_synchronize_778914_003F72.png" height = "90" width = "90"> **Do** |
| --- | --- | 
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We logged in to mtl.how/sim and explored the results of the Base Case (bc) in the Expanded Outputs section to prepare for experiment 1. | [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We will test a dynamic hypothesis by running experiment 1 and comparing results against the bc.

### After this MTL session, you will be able to:

<!-- Learning Objectives Icon --> 
<img src = "https://github.com/lzim/teampsd/blob/master/resources/icons/we_decided_learning_objectives.png" height = "90" width = "90" style ="display: inline-block"/> 

## Learning Objectives

1. Describe the systems story your team believes will cause the outcomes you expect to observe in your experiment.
2. Test your dynamic hypothesis about your team's clinical priority.
3. Apply systems thinking to describe your team's findings, insights and conclusions from your experiment.

### Let's get started:

## In-session Exercise (30 minutes): Running an experiment

1.	Log in to the team world at mtl.how/sim.

2.	In the middle tile on *MTL* Home, you will see the "Experiment Maintenance" tile in the middle of the screen. This is where you can review your saved runs by clicking on the down arrow to the right of "Experiment Maintenance" title in the blue bar.  

   + In this tile you are able to *Delete*, *Rename*, or *Export* your experiments. Review your saved runs.  
  
   + A team may need to rename experiments if they want to be sure they are able to differentiate between experiments or if they incorrectly named a file in a prior session. If you need to rename any of your saved runs, click on the box to the left of the file name and click on the word *Rename*. You can then change the name of the file and click on the save button.  

3.	On the right side of the *MTL* Home page, you will see the "Team Data Menu Maintenance" tile. In this tile you are able to *Delete*, *Rename*, or *Add* data files. Review the data files you have uploaded for use and make sure you have the data file you want. 

4.	You can *Join Current Session* or *Start a New Session* in the desired module by clicking in the circle to the right of one of those titles and then click on "Play." 

   + As a reminder, the available modules are Care Coordination or CC, Medication Management or MM, Psychotherapy or PSY, Aggregate or AGG, and Suicide Prevention or SP.  
   
   + If you *Start a New Session* you will need to select the team data file you would like to use. Click on the "Select Team Data" icon. A pop-up box will appear on your computer screen with the text, "Please select a model input file." Click on the blue down arrow next to the text "Please select team data" and choose the data file you would like to use in an experiment.  

5.	The main model tile is in the center of your screen. The Output and Experiment sections are on the right side of the model. To refresh your memory and pick up where you left off in your *MTL* learning, expand the Experiments section by clicking on the white down arrow in the blue bar. You will see the phrase, "Select Previous Experiment to Set Experimental Values to a Former State." 

   + Click on the red down arrow and select the base case experiment from the last session.  
   + When you click the red "Go" button, a blue and white pop up box will appear with the title "Review Previous Settings." Because you've selected the base case experiment, all of the values showing in the Experimental Values box should show either BC or 1.  
   + You will also want to check the box next to the text "Include text from this session in Expanded Outputs text fields?"  
   + As a reminder, the text fields are: Our Question, Our Hypothesis, Our Findings, Our Decisions. To bring up the text boxes for easy review, click on the Output section. Click on Expand. Click on the layered squares or windows in the upper right corner of the blue bar to make the text box smaller so it's easy to review the text in the text boxes and main model diagram.  

6.	Next, let's click on "reveal complexity" so the learner can view the whole model. Let's study the model diagram and team data.  
  + First, explore the Appointments section of the model and see how Appointment Supply links to a number of variables.  
  + Then, examine the Patients sections of the model. Notice how the different gauges and rectangles are linked and what causes them to increase or decrease.  
  + Finally see how the Patients and Appointments interact in the model for example by examining appointment supply and return visit interval.  Remember, red boxes are read into the model from team data.  
  + As a team, we decide what change to experiment with in the model. To make that decision, we should ask: 1) How do we think things will change over time if choose a specific variable to change?, and 2) What relationships in the system will interact if we make the change? Ultimately, the team should choose changes that might give the desired result that links to the team vision and team need. 

7.	Let's create a new experiment building off of the previous one which focused on the base case - what happens if we make no new decisions. The first step is to revise the text in all the text boxes to reflect the experiment you want to do now: 

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_question.png" height = "50" width = "50" style = "display: inline-block"/>](http://mtl.how/sim) **Our Question.** *Briefly describe what your team wants to learn from this experiment.* 

**CC** - What will happen to the Starting Rate and New Patient Wait Time if we increase the Appointment Supply of care coordination appointments overall?

**MM** - How could we serve more patients with specific conditions, like OUD, with our existing staffing levels?

**PSY** - What if we graduate more patients who complete 8 or more psychotherapy sessions in their first 3 months? What is the effect of working to increase the proportion of patients who 'complete' an evidence-based dose of PSY and then graduate from just 4% to 75%, over time, on (1) the number of patients who complete and are then 'done'? and (2) on the supply of available appts for new patients?

**AGG** - How can we manage the loss of two providers and still manage patient needs for PSY? What would happen if we change the PSY RVI to 2 weeks and the RVI for EB PSY to just 1 week (from 17 weeks)?

**SP** - What if we implemented measurement-based care in our team?

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_hypothesis.png" height = "50" width = "50" style = "display: inline-block"/>](http://mtl.how/sim) **Our Hypothesis.** *Outline the systems story your team believes will cause the outcomes your team expects to observe.*

**CC** - Increasing the CC Appointment Supply will make more Appointments available for both new and existing CC patients. The Additional Appointment Supply for New CC Patients will increase the Starting Rate and lower New Patient Wait Times.

**MM** - If our referral rate for OUD is 2 pts per month (0.5 per week), and we allocate 40% of our x-waiver slots to OUD treatment, and 40% to Other Needs, and we change our RVI for depression to 12 weeks, and the RVI for OUD to 4 weeks (in line with our quality standards), then we will serve more OUD patients with our existing team staff, without increasing the wait time for new depression patients.

**PSY** - We expect that if we increase our completers who graduate to 75%, then we'll free up more slots in the clinic for more patients to start psychoterhapy/EBPsy. We hypothesize that an increasing the complete and graduate rate from 4% to 75% will results in a jump from about 4 patients to about 75 patients graduating during the same time period. We also expect that by increasing the graduation rate for any one who has received 8 or more sessions of PSY, we will increase the number of appt slots for new patients starting PSY.

**AGG** - We expect to see the number of PSY patients in service to go down within the first year, and then to reach a new level that is well below 300. If the numbers were down to 150 patients, then we may be able to handle the staff reduction.

**SP** – If we implement measurement based care in our GMH team, then care quality will improve (specifically through reductions in Time to Improve and Time to UnFlag, and an increase in the Time to Ending). Also, how long it takes clinicians to see changes in their patients will also improve (seen in a reduction in Time to Detect). We expect to be able to effectively diagnose and treat patients faster, reducing the number of high-symptom patients in care, and thus reducing the number of patients who receive high risk flags.
However, low symptom patients are in care for longer than before, reducing the number of openings for new patients. These patients will make up more and more of our total – as there will be both more flowing in (due to higher Improvement Rate) and fewer flowing out (due to the lower Ending Rate). With fewer openings, wait times to start with our team should increase.  

  + An example of a hypothesis statement is: "Our team thinks we can create more capacity for seeing EBPsy patients if we slightly lengthen the average return-to-clinic visit interval for our Psy patients. To test this, we will try increasing the Psy RVI from 10 to 11 weeks."  

8.	Slide the Text box to the left, over the model diagram. This will allow you to adjust experiment sliders for the new experiment.  
  + Keep in mind that the previous run’s settings are in effect -- in this case, we have only run the BC or base case so the default values from the team data are the previous run settings.  
  + Adjust the sliders of the variable or variables you selected.  
  + A quick tip -- make note of the service or services you selected to change and the new values, that is, what you changed the numbers to, so you have that information available when you save the experiment.  

9.	In the Experiment Timeline box above the main model diagram, click the green *Run* button.  

10. Go to Output, click *Save* in the upper right corner. Name this run according to the variables you changed. This is where your notes about the services and numbers you changed for this experiment will come in handy.  
  + To name the run, click on the down arrow next to Variable, choose the variable name you changed, for example, Appointment Supply or Return Visit Interval. Click *Add*. This will insert an abbreviation of that variable into the experiment name.  
  + Click on the down arrow next to Service, choose the service you adjusted, for example, Psy, Medication Management or Adjunctive services. Click *Add*.  
  + Finally, click on the down arrow next to Number, choose the number that represents the new value you used in your experiment.  
  + Click *Save* (not Save & Reset, just Save). The date will automatically be added to the name of the saved experiment.  

11.	The Outputs section contains the Results Dashboard. It is here you can compare the new experiment to your base case run.  
  + There are six charts in the dashboard. To see the default set of charts for a specific service, go to the main model diagram Experiment Timeline box and under "Display Patient Services" click on the service for the specific charts you want to review.  
  + You can review individual charts by expanding the Output tile on the right and clicking on the blue arrow under the individual chart. You can also click on "Expand" to see all six charts at one time.  
  + To change the charts, click on the down arrows under the chart to bring up different variables or services. Examine the differences between the base case and the current experimental run. Record what you learned in the *Our Findings* text box:

[<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_findings.png" height = "50" width = "50" style = "display: inline-block"/>](http://mtl.how/sim) **Our Findings.** *Describe your team's findings, insights and conclusions from this experiment.* 

**CC** - Increasing the supply of Appointment Supply for New CC Patients does increase the new CC patient weekly Starting Rate, which reduces new CC patients Waiting to Start.

**MM** - We found that if we allocate 50% of our x-waiver provider appointments to OUD, in the long run instead of only starting ½ patient per week (1 every other week), we can start 3 patients in OUD per week. But dropping the appointment supply for our *Other* patients meant we could not start any of them in care for a while until some existing patients completed and moved on. A backlog built up, which caused referrals to slow. When we were eventually able to start *Other* patients, the backlog dropped so referrals picked up again, and we established a new steady state with about 15 *Other* diagnosis patients waiting to start and about 170 in care.

**PSY** - We found that the total number of patients served by the team increased from N=371 to N=460. Of the 460, n=358 were Initiators and n=132 were Completers. Among Completers, n=99 graduated and were done (75%, as we expected). Regarding the starting rate for new patients, it increased from about 3.8 pts/wk to about 4.8 pts/wk. our hypotheses was supported. This dramatically increases the number of patients in PSY who are receiving an evidence base dose of therapy and supports the team in taking on more new patients, about one more new pt/wk (or 4 new ones per month, or 48 new ones annually!)

**AGG** - Our hypothesis was supported! We see that implementing a much shorter RVI for PSY patients show a steady reduction in the number of PSY patients in service, from more than 300 in our BC to less than a 100 after two years. Booking rates for PSY climb initially, but then drop off and level out just a bit higher than baseline! One concern is that MM patients in service also drops from about 1000 to 900.

**SP** – As predicted, we see a dramatic shift in patient from “high symptom” to “low symptom,” as both detection and care quality improve – the ratio of high to low symptom patients drops from 0.6:1 to 0.2:1 over two years. The number of patients with a suicide flag decreases by more than 50%, as more high symptom patients have their symptoms addressed before they can be flagged in the first place. However, the initial predicted reduction in Ending Rate is off-set by long-term increases in the Recommend Step Down Rate, thus not permanently impacting the new patient start rate. Both new patient starts and wait times in our clinic increase in the short-term, but fall below our historical average by 3 months, and continue to fall for the next year. However, because there have been no changes in Primary Care, wait times for stepping down to PC go up substantially – from 22 to 38 weeks.

+ You walked through the system story for both Appointments and Patients. With your text box on the right side of the screen, revisit the model diagram and outline the systems story your team believes will cause the outcomes your team expects to observe. Begin to craft the text for the *Our Hypothesis* box. A good hypothesis will include the proposed change our team will make, the services that will be impacted, how the team data values will be changed from base case, and what we expect to see as a result of the change.

11.	Discuss and record what changes you may want to make in the clinic and what further experiments you want to run. 

 [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/icons/mtl_decisions.png" height = "50" width = "50" style = "display: inline-block"/>](http://mtl.how/sim) **Our Decisions.** *Based on what you learned in this experiment, what changes are you ready to make in your practice?*

**CC** - Next time we will experiment with adjusting our Return Visit Interval.

**MM** - Although we were glad to see that we could care for more OUD patients with our available staffing, we are concerned that if all we do is shift several of our Other appointments to OUD, we won't be able to help as many Other patients. We decided to experiment with Return to Clinic Visit Intervals as a possible alternate solution.

**PSY** - For our next experiment, since we have now affirmed that we have additional appt capacity for new (and existing patients), we would like to explore how changing Initiators who Complete from the base case rate of 37% to 75% might impact the number of patients who complete and graduate. This will be the only change we make, so that we can see the effect clearly.

**AGG** - Now that we have reduced the RVI for PSY and EB PSY, we can look to see what gains in managing our patients may be achieved by rebalancing our service mix. We'll see what happens if we invest in doing more EB PSY and less PSY, but keeping the proportion of other services more or less as before.

**SP** – In this experiment, we see a strong connection between changes made in our team and wait times for downstream teams. We should run an experiment that explores these connections and gauge the impacts of implementing stepped care between GMH and PC/PCMHI.

+ Type in the *Our Decision* text box a question that describes what your team wants to learn from changing a specific variable or variables in the model.

12. Save and Reset when ready.
 
### That's it for _Modeling to Learn_ how to test a dynamic hypothesis. Next is our Done/Do review.
 
Today we ran and experiment and compared the results against the base case. Before next time, please explore the base case and experiment results and draft a dynamic hypothesis to prepare for experiment 2. 

## Done and Do (15 minutes)
<!-- Do/Done Tables -->
| <img src = "https://raw.githubusercontent.com/lzim/teampsd/hexagon_icons/np_hexagon-check-mark_309690_003F72.png" height = "80" width = "80"> **Done** | <img src = "https://raw.githubusercontent.com/lzim/teampsd/hexagon_icons/np_synchronize_778914_003F72.png" height = "90" width = "90"> **Do** |
| --- | --- | 
| [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) We ran experiment 1 and compared results against the bc. | [<img src = "https://raw.githubusercontent.com/lzim/teampsd/master/resources/logos/mtl_how_sim.png" height = "75" width = "110">](http://mtl.how/sim) Explore the bc and experiment 1, and draft a dynamic hypothesis to prepare for experiment 2. | 

## Until next time, thank you for *Modeling to Learn*!

